{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "c79e56b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import os\n",
    "\n",
    "# Folder containing the files\n",
    "folder_path = \"audio_train_new/\"\n",
    "\n",
    "# Get a list of all files in the folder\n",
    "files = os.listdir(folder_path)\n",
    "count=0\n",
    "# Iterate over each file in the folder\n",
    "for i, file in enumerate(files):\n",
    "    # Check if the file name contains \"音频\"\n",
    "    if \"stranger\" in file:\n",
    "        # Generate the new file name\n",
    "        new_file_name = f\"stranger_{count}.wav\"\n",
    "        # Construct the old and new file paths\n",
    "        old_file_path = os.path.join(folder_path, file)\n",
    "        new_file_path = os.path.join(folder_path, new_file_name)\n",
    "        # Rename the file\n",
    "        os.rename(old_file_path, new_file_path)\n",
    "        count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "8c802b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "###################   rename specific files ###############\n",
    "\n",
    "import os\n",
    "\n",
    "folder_path = \"audio_train_new\"  # Path to the folder containing the audio files\n",
    "\n",
    "# Loop through files in the folder\n",
    "for filename in os.listdir(folder_path):\n",
    "    # Check if the filename matches the pattern \"cyhh_audio_i\" with i from 101 to 160\n",
    "    if filename.startswith(\"haoyu_\") and filename.endswith(\".wav\"):\n",
    "        try:\n",
    "            file_number = int(filename.split(\"_\")[-1].split(\".\")[0])\n",
    "            if 101 <= file_number <= 160:\n",
    "                # Rename the file to \"stranger_audio_i\"\n",
    "                new_filename = filename.replace(\"data_\", \"haoyu_\")\n",
    "                os.rename(os.path.join(folder_path, filename), os.path.join(folder_path, new_filename))\n",
    "                print(f\"Renamed {filename} to {new_filename}\")\n",
    "        except ValueError:\n",
    "            # Skip files that don't match the expected format\n",
    "            continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75180447",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "音频文件信息:\n",
      "  文件名: audio_files/haoyu_audio_31.wav\n",
      "  时长: 3.53 秒\n",
      "  采样率: 48000 Hz\n",
      "  通道数: 2\n"
     ]
    }
   ],
   "source": [
    "import audioread\n",
    "\n",
    "# 音频文件路径\n",
    "audio_file = \"audio_files/haoyu_audio_31.wav\"\n",
    "\n",
    "try:\n",
    "    # 使用audioread打开音频文件\n",
    "    with audioread.audio_open(audio_file) as f:\n",
    "        print(\"音频文件信息:\")\n",
    "        print(f\"  文件名: {audio_file}\")\n",
    "        print(f\"  时长: {f.duration:.2f} 秒\")\n",
    "        print(f\"  采样率: {f.samplerate} Hz\")\n",
    "        print(f\"  通道数: {f.channels}\")\n",
    "        \n",
    "except audioread.NoBackendError:\n",
    "    print(\"无法找到支持的后端，无法打开音频文件。\")\n",
    "except audioread.DecodeError:\n",
    "    print(\"无法解码音频文件。可能是因为不支持的编码格式。\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9a26092",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras import layers, models, utils\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6aea4988",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract MFCC features from audio files\n",
    "def extract_features(file_path, mfcc=True, chroma=True, mel=True,sr=22050):\n",
    "    audio_data, _ = librosa.load(file_path)  # Load audio data directly without a context manager\n",
    "    features = []\n",
    "    if mfcc:\n",
    "        mfccs = np.mean(librosa.feature.mfcc(y=audio_data, sr=sr, n_mfcc=13), axis=1)\n",
    "        features.extend(mfccs)\n",
    "    if chroma:\n",
    "        chroma = np.mean(librosa.feature.chroma_stft(y=audio_data, sr=sr), axis=1)\n",
    "        features.extend(chroma)\n",
    "    if mel:\n",
    "        mel = np.mean(librosa.feature.melspectrogram(y=audio_data, sr=sr), axis=1)\n",
    "        features.extend(mel)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d52bdebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load audio files and extract features\n",
    "def load_data(file_paths,sr):\n",
    "    X = []\n",
    "    y = []\n",
    "    for file_path in file_paths:\n",
    "        features = extract_features(file_path,sr)\n",
    "        X.append(features)\n",
    "        # Assume file name format is \"<speaker_id>_<other_info>.wav\"\n",
    "#         print(file_path)\n",
    "        label = file_path.split(\"/\")[-1].split(\"_\")[0]\n",
    "        y.append(label)\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "98615c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Function to collect paths of all .wav files in a directory\n",
    "def collect_audio_paths(directory):\n",
    "    audio_paths = []\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            audio_paths.append(os.path.join(root, file))\n",
    "    return audio_paths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e60548c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X: (295, 153)\n",
      "Shape of y_encoded: (295,)\n",
      "(265, 153, 1)\n",
      "(265,)\n",
      "153\n"
     ]
    }
   ],
   "source": [
    "# Load audio files and corresponding labels\n",
    "# Directory containing .wav files\n",
    "audio_directory = \"audio_train_new/\"\n",
    "# Sampling Rate\n",
    "sr= 22050\n",
    "\n",
    "class_names = [\"cyhh\",\"haoyu\",\"stranger\"]\n",
    "# Collect paths of .wav files\n",
    "file_paths = collect_audio_paths(audio_directory)\n",
    "\n",
    "X, y = load_data(file_paths,sr)\n",
    "# print(y)\n",
    "# Encode labels as integers\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "# print(y_encoded)\n",
    "# print(\"X:\",X)\n",
    "# print(\"y:\",y)\n",
    "print(\"Shape of X:\", X.shape)\n",
    "print(\"Shape of y_encoded:\", y_encoded.shape)\n",
    "shape_x_0=X.shape[0]\n",
    "X=X.reshape((shape_x_0,153,1))\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.1, random_state=42)\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "input_shape=X_train.shape[1]\n",
    "print(input_shape)\n",
    "\n",
    "# print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "734310c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def residual_block(x, filters, conv_num=3, activation=\"relu\"):\n",
    "    # Shortcut\n",
    "    s = keras.layers.Conv1D(filters, 1, padding=\"same\")(x)\n",
    "    for i in range(conv_num - 1):\n",
    "        x = keras.layers.Conv1D(filters, 3, padding=\"same\")(x)\n",
    "        x = keras.layers.Activation(activation)(x)\n",
    "    x = keras.layers.Conv1D(filters, 3, padding=\"same\")(x)\n",
    "    x = keras.layers.Add()([x, s])\n",
    "    x = keras.layers.Activation(activation)(x)\n",
    "    x = keras.layers.MaxPool1D(pool_size=2, strides=2, padding='same')(x)  # Adjust the padding here\n",
    "    return x\n",
    "\n",
    "\n",
    "def build_model(input_shape, num_classes):\n",
    "    inputs = keras.layers.Input(shape=input_shape, name=\"input\")\n",
    "\n",
    "    x = residual_block(inputs, 16, 2)\n",
    "    x = residual_block(x, 32, 2)\n",
    "    x = residual_block(x, 64, 3)\n",
    "    x = residual_block(x, 128, 3)\n",
    "    x = residual_block(x, 128, 3)\n",
    "\n",
    "    x = keras.layers.AveragePooling1D(pool_size=3, strides=3)(x)\n",
    "    x = keras.layers.Flatten()(x)\n",
    "    x = keras.layers.Dense(256, activation=\"relu\")(x)\n",
    "    x = keras.layers.Dense(128, activation=\"relu\")(x)\n",
    "\n",
    "    outputs = keras.layers.Dense(num_classes, activation=\"softmax\", name=\"output\")(x)\n",
    "\n",
    "    return keras.models.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f9cfb94c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input (InputLayer)             [(None, 153, 1)]     0           []                               \n",
      "                                                                                                  \n",
      " conv1d_1 (Conv1D)              (None, 153, 16)      64          ['input[0][0]']                  \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 153, 16)      0           ['conv1d_1[0][0]']               \n",
      "                                                                                                  \n",
      " conv1d_2 (Conv1D)              (None, 153, 16)      784         ['activation[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d (Conv1D)                (None, 153, 16)      32          ['input[0][0]']                  \n",
      "                                                                                                  \n",
      " add (Add)                      (None, 153, 16)      0           ['conv1d_2[0][0]',               \n",
      "                                                                  'conv1d[0][0]']                 \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, 153, 16)      0           ['add[0][0]']                    \n",
      "                                                                                                  \n",
      " max_pooling1d (MaxPooling1D)   (None, 77, 16)       0           ['activation_1[0][0]']           \n",
      "                                                                                                  \n",
      " conv1d_4 (Conv1D)              (None, 77, 32)       1568        ['max_pooling1d[0][0]']          \n",
      "                                                                                                  \n",
      " activation_2 (Activation)      (None, 77, 32)       0           ['conv1d_4[0][0]']               \n",
      "                                                                                                  \n",
      " conv1d_5 (Conv1D)              (None, 77, 32)       3104        ['activation_2[0][0]']           \n",
      "                                                                                                  \n",
      " conv1d_3 (Conv1D)              (None, 77, 32)       544         ['max_pooling1d[0][0]']          \n",
      "                                                                                                  \n",
      " add_1 (Add)                    (None, 77, 32)       0           ['conv1d_5[0][0]',               \n",
      "                                                                  'conv1d_3[0][0]']               \n",
      "                                                                                                  \n",
      " activation_3 (Activation)      (None, 77, 32)       0           ['add_1[0][0]']                  \n",
      "                                                                                                  \n",
      " max_pooling1d_1 (MaxPooling1D)  (None, 39, 32)      0           ['activation_3[0][0]']           \n",
      "                                                                                                  \n",
      " conv1d_7 (Conv1D)              (None, 39, 64)       6208        ['max_pooling1d_1[0][0]']        \n",
      "                                                                                                  \n",
      " activation_4 (Activation)      (None, 39, 64)       0           ['conv1d_7[0][0]']               \n",
      "                                                                                                  \n",
      " conv1d_8 (Conv1D)              (None, 39, 64)       12352       ['activation_4[0][0]']           \n",
      "                                                                                                  \n",
      " activation_5 (Activation)      (None, 39, 64)       0           ['conv1d_8[0][0]']               \n",
      "                                                                                                  \n",
      " conv1d_9 (Conv1D)              (None, 39, 64)       12352       ['activation_5[0][0]']           \n",
      "                                                                                                  \n",
      " conv1d_6 (Conv1D)              (None, 39, 64)       2112        ['max_pooling1d_1[0][0]']        \n",
      "                                                                                                  \n",
      " add_2 (Add)                    (None, 39, 64)       0           ['conv1d_9[0][0]',               \n",
      "                                                                  'conv1d_6[0][0]']               \n",
      "                                                                                                  \n",
      " activation_6 (Activation)      (None, 39, 64)       0           ['add_2[0][0]']                  \n",
      "                                                                                                  \n",
      " max_pooling1d_2 (MaxPooling1D)  (None, 20, 64)      0           ['activation_6[0][0]']           \n",
      "                                                                                                  \n",
      " conv1d_11 (Conv1D)             (None, 20, 128)      24704       ['max_pooling1d_2[0][0]']        \n",
      "                                                                                                  \n",
      " activation_7 (Activation)      (None, 20, 128)      0           ['conv1d_11[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_12 (Conv1D)             (None, 20, 128)      49280       ['activation_7[0][0]']           \n",
      "                                                                                                  \n",
      " activation_8 (Activation)      (None, 20, 128)      0           ['conv1d_12[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_13 (Conv1D)             (None, 20, 128)      49280       ['activation_8[0][0]']           \n",
      "                                                                                                  \n",
      " conv1d_10 (Conv1D)             (None, 20, 128)      8320        ['max_pooling1d_2[0][0]']        \n",
      "                                                                                                  \n",
      " add_3 (Add)                    (None, 20, 128)      0           ['conv1d_13[0][0]',              \n",
      "                                                                  'conv1d_10[0][0]']              \n",
      "                                                                                                  \n",
      " activation_9 (Activation)      (None, 20, 128)      0           ['add_3[0][0]']                  \n",
      "                                                                                                  \n",
      " max_pooling1d_3 (MaxPooling1D)  (None, 10, 128)     0           ['activation_9[0][0]']           \n",
      "                                                                                                  \n",
      " conv1d_15 (Conv1D)             (None, 10, 128)      49280       ['max_pooling1d_3[0][0]']        \n",
      "                                                                                                  \n",
      " activation_10 (Activation)     (None, 10, 128)      0           ['conv1d_15[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_16 (Conv1D)             (None, 10, 128)      49280       ['activation_10[0][0]']          \n",
      "                                                                                                  \n",
      " activation_11 (Activation)     (None, 10, 128)      0           ['conv1d_16[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_17 (Conv1D)             (None, 10, 128)      49280       ['activation_11[0][0]']          \n",
      "                                                                                                  \n",
      " conv1d_14 (Conv1D)             (None, 10, 128)      16512       ['max_pooling1d_3[0][0]']        \n",
      "                                                                                                  \n",
      " add_4 (Add)                    (None, 10, 128)      0           ['conv1d_17[0][0]',              \n",
      "                                                                  'conv1d_14[0][0]']              \n",
      "                                                                                                  \n",
      " activation_12 (Activation)     (None, 10, 128)      0           ['add_4[0][0]']                  \n",
      "                                                                                                  \n",
      " max_pooling1d_4 (MaxPooling1D)  (None, 5, 128)      0           ['activation_12[0][0]']          \n",
      "                                                                                                  \n",
      " average_pooling1d (AveragePool  (None, 1, 128)      0           ['max_pooling1d_4[0][0]']        \n",
      " ing1D)                                                                                           \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 128)          0           ['average_pooling1d[0][0]']      \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 256)          33024       ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 128)          32896       ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " output (Dense)                 (None, 3)            387         ['dense_1[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 401,363\n",
      "Trainable params: 401,363\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#  Build and Compile the Model\n",
    "model = build_model(((input_shape,1)), len(class_names))\n",
    "model.summary()\n",
    "\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "acadeb4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "67/67 [==============================] - 10s 33ms/step - loss: 1.7033 - accuracy: 0.4868 - val_loss: 0.6308 - val_accuracy: 0.6667\n",
      "Epoch 2/20\n",
      "67/67 [==============================] - 1s 17ms/step - loss: 0.5143 - accuracy: 0.6830 - val_loss: 0.4003 - val_accuracy: 0.7333\n",
      "Epoch 3/20\n",
      "67/67 [==============================] - 1s 22ms/step - loss: 0.7989 - accuracy: 0.6604 - val_loss: 0.5097 - val_accuracy: 0.6667\n",
      "Epoch 4/20\n",
      "67/67 [==============================] - 2s 24ms/step - loss: 0.4275 - accuracy: 0.7736 - val_loss: 0.2367 - val_accuracy: 0.9667\n",
      "Epoch 5/20\n",
      "67/67 [==============================] - 1s 16ms/step - loss: 0.3577 - accuracy: 0.8642 - val_loss: 0.4032 - val_accuracy: 0.8667\n",
      "Epoch 6/20\n",
      "67/67 [==============================] - 1s 19ms/step - loss: 0.3623 - accuracy: 0.8755 - val_loss: 0.2768 - val_accuracy: 0.9000\n",
      "Epoch 7/20\n",
      "67/67 [==============================] - 1s 16ms/step - loss: 0.2013 - accuracy: 0.9509 - val_loss: 0.3408 - val_accuracy: 0.8667\n",
      "Epoch 8/20\n",
      "67/67 [==============================] - 2s 26ms/step - loss: 0.1133 - accuracy: 0.9509 - val_loss: 0.0268 - val_accuracy: 1.0000\n",
      "Epoch 9/20\n",
      "67/67 [==============================] - 1s 16ms/step - loss: 0.1066 - accuracy: 0.9774 - val_loss: 0.0575 - val_accuracy: 0.9667\n",
      "Epoch 10/20\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 0.0694 - accuracy: 0.9849 - val_loss: 0.1939 - val_accuracy: 0.9333\n",
      "Epoch 11/20\n",
      "67/67 [==============================] - 1s 18ms/step - loss: 0.0361 - accuracy: 0.9925 - val_loss: 0.1439 - val_accuracy: 0.9333\n",
      "Epoch 12/20\n",
      "67/67 [==============================] - 2s 27ms/step - loss: 0.1781 - accuracy: 0.9736 - val_loss: 0.0576 - val_accuracy: 0.9667\n",
      "Epoch 13/20\n",
      "67/67 [==============================] - 2s 25ms/step - loss: 0.0847 - accuracy: 0.9774 - val_loss: 0.0145 - val_accuracy: 1.0000\n",
      "Epoch 14/20\n",
      "67/67 [==============================] - 2s 26ms/step - loss: 0.0310 - accuracy: 0.9962 - val_loss: 0.2095 - val_accuracy: 0.9333\n",
      "Epoch 15/20\n",
      "67/67 [==============================] - 2s 24ms/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 0.0105 - val_accuracy: 1.0000\n",
      "Epoch 16/20\n",
      "67/67 [==============================] - 2s 28ms/step - loss: 4.3267e-04 - accuracy: 1.0000 - val_loss: 0.0029 - val_accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "67/67 [==============================] - 2s 25ms/step - loss: 1.6911e-04 - accuracy: 1.0000 - val_loss: 0.0024 - val_accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "67/67 [==============================] - 2s 28ms/step - loss: 1.2187e-04 - accuracy: 1.0000 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "67/67 [==============================] - 2s 23ms/step - loss: 9.3442e-05 - accuracy: 1.0000 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "67/67 [==============================] - 2s 24ms/step - loss: 7.2054e-05 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Test Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=20, batch_size=4, validation_data=(X_test, y_test))\n",
    "# model.fit(X_train, y_train, epochs=20, batch_size=4)\n",
    "\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Accuracy: {accuracy}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1ff26abf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "153\n",
      "1/1 [==============================] - 1s 670ms/step\n",
      "[[0.18244793 0.81461793 0.0029342 ]]\n",
      "Predicted label: haoyu\n"
     ]
    }
   ],
   "source": [
    "# preprocessing\n",
    "# test_feature= extract_features(\"test_audio/cyhh_audio_1.wav\", mfcc=True, chroma=True, mel=True,sr=22050)\n",
    "test_feature= extract_features(\"audio_test_new/test.wav\", mfcc=True, chroma=True, mel=True,sr=22050)\n",
    "# test_feature= extract_features(\"audio_files/haoyu_audio_70.wav\", mfcc=True, chroma=True, mel=True,sr=22050)\n",
    "print(len(test_feature))\n",
    "test_feature= np.array(test_feature)\n",
    "# print(test_feature.shape)\n",
    "test_feature= test_feature.reshape(1,153,1)\n",
    "# print(test_feature.shape)\n",
    "\n",
    "# Make prediction\n",
    "\n",
    "predictions = model.predict(test_feature)\n",
    "print(predictions)\n",
    "# Post-process predictions (e.g., choose the class with the highest probability)\n",
    "predicted_label = np.argmax(predictions)\n",
    "\n",
    "print(\"Predicted label:\", class_names[predicted_label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b04d967b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 82ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 126ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 171ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "Wrong Prediction:  cyhh\n",
      "Correct Label: haoyu\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 101ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "Wrong Prediction:  cyhh\n",
      "Correct Label: haoyu\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "Wrong Prediction:  cyhh\n",
      "Correct Label: haoyu\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "Wrong Prediction:  cyhh\n",
      "Correct Label: haoyu\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "Wrong Prediction:  cyhh\n",
      "Correct Label: haoyu\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "Wrong Prediction:  cyhh\n",
      "Correct Label: haoyu\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 133ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "Wrong Prediction:  haoyu\n",
      "Correct Label: test.wav\n",
      "Total samples: 117\n",
      "Success count: 110\n",
      "Accuracy: 0.94\n"
     ]
    }
   ],
   "source": [
    "########## calculate the success rate #####################\n",
    "import os\n",
    "import librosa  # For audio processing\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load your pre-trained model\n",
    "# Replace this with code to load your pre-trained model\n",
    "\n",
    "folder_path = \"audio_test_new\"  # Path to the folder containing the test audio files\n",
    "success_count = 0\n",
    "total_count = 0\n",
    "true_labels = []\n",
    "predicted_labels = []\n",
    "\n",
    "# Loop through files in the folder\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith(\".wav\"):\n",
    "        # Extract label from filename\n",
    "        label = filename.split(\"_\")[0]\n",
    "\n",
    "        # Load audio file\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        # preprocessing\n",
    "        test_feature= extract_features(file_path, mfcc=True, chroma=True, mel=True,sr=22050)\n",
    "        # test_feature= extract_features(\"audio_files/haoyu_audio_70.wav\", mfcc=True, chroma=True, mel=True,sr=22050)\n",
    "        test_feature= np.array(test_feature)\n",
    "        test_feature= test_feature.reshape(1,153,1)\n",
    "        # print(test_feature.shape)\n",
    "\n",
    "        # Make prediction\n",
    "        predictions = model.predict(test_feature)\n",
    "#         print(predictions)\n",
    "        # Post-process predictions (e.g., choose the class with the highest probability)\n",
    "        predicted_label_index = np.argmax(predictions)\n",
    "        predicted_label=class_names[predicted_label_index]\n",
    "        # Update counts and lists for accuracy calculation\n",
    "        if label == predicted_label:\n",
    "            success_count += 1\n",
    "        else:\n",
    "            print(\"Wrong Prediction: \",predicted_label)\n",
    "            print(\"Correct Label:\",label)\n",
    "        total_count += 1\n",
    "        true_labels.append(label)\n",
    "        predicted_labels.append(predicted_label)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "\n",
    "print(f\"Total samples: {total_count}\")\n",
    "print(f\"Success count: {success_count}\")\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "d11076d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: speaker_recognition_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: speaker_recognition_model\\assets\n"
     ]
    }
   ],
   "source": [
    "# Save the model for future use\n",
    "model.save(\"speaker_recognition_model\")\n",
    "\n",
    "# Save label encoder for future use\n",
    "np.save(\"label_encoder.npy\", label_encoder.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a973d153",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO:\n",
    "# 1. Dynamic range quantization\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model(\"speaker_recognition_model\")\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "tflite_dy_range_quant_model = converter.convert()\n",
    "# Save the model.\n",
    "with open('dynamicQuant_speaker_recogniztion.tflite', 'wb') as f:\n",
    "    f.write(tflite_dy_range_quant_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf28af12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
