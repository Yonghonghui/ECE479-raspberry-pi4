{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/haoyuh3/raspberry-pi4/blob/main/extra_with_resnet_data_augument.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rX8mhOLljYeM"
      },
      "source": [
        "##### Copyright 2019 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "BZSlp3DAjdYf"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3wF5wszaj97Y"
      },
      "source": [
        "# TensorFlow 2 quickstart for experts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DUNzJc4jTj6G"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://www.tensorflow.org/tutorials/quickstart/advanced\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" />View on TensorFlow.org</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/quickstart/advanced.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/tensorflow/docs/blob/master/site/en/tutorials/quickstart/advanced.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a href=\"https://storage.googleapis.com/tensorflow_docs/docs/site/en/tutorials/quickstart/advanced.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\" />Download notebook</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hiH7AC-NTniF"
      },
      "source": [
        "This is a [Google Colaboratory](https://colab.research.google.com/notebooks/welcome.ipynb) notebook file. Python programs are run directly in the browserâ€”a great way to learn and use TensorFlow. To follow this tutorial, run the notebook in Google Colab by clicking the button at the top of this page.\n",
        "\n",
        "1. In Colab, connect to a Python runtime: At the top-right of the menu bar, select *CONNECT*.\n",
        "2. Run all the notebook code cells: Select *Runtime* > *Run all*."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eOsVdx6GGHmU"
      },
      "source": [
        "Download and install TensorFlow 2. Import TensorFlow into your program:\n",
        "\n",
        "Note: Upgrade `pip` to install the TensorFlow 2 package. See the [install guide](https://www.tensorflow.org/install) for details."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QS7DDTiZGRTo"
      },
      "source": [
        "Import TensorFlow into your program:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0trJmd6DjqBZ",
        "outputId": "3f5424e0-2584-4b20-b27d-c9e37a277760",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow version: 2.15.0\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "print(\"TensorFlow version:\", tf.__version__)\n",
        "\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D\n",
        "from tensorflow.keras import Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7NAbSZiaoJ4z"
      },
      "source": [
        "Load and prepare the [MNIST dataset](http://yann.lecun.com/exdb/mnist/)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JqFRS6K07jJs",
        "outputId": "87b1b2ac-03cc-499f-926c-a253a3d0841b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 28, 28)\n",
            "(10000, 28, 28)\n",
            "(60000, 28, 28, 1)\n",
            "(10000, 28, 28, 1)\n"
          ]
        }
      ],
      "source": [
        "mnist = tf.keras.datasets.mnist\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "print(x_train.shape)\n",
        "print(x_test.shape)\n",
        "# Add a channels dimension\n",
        "x_train = x_train[..., tf.newaxis].astype(\"float32\")\n",
        "x_test = x_test[..., tf.newaxis].astype(\"float32\")\n",
        "print(x_train.shape)\n",
        "print(x_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k1Evqx0S22r_"
      },
      "source": [
        "Use `tf.data` to batch and shuffle the dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Iu_quO024c2"
      },
      "outputs": [],
      "source": [
        "train_ds = tf.data.Dataset.from_tensor_slices(\n",
        "    (x_train, y_train)).shuffle(10000).batch(32)\n",
        "\n",
        "test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(32)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BPZ68wASog_I"
      },
      "source": [
        "Build the `tf.keras` model using the Keras [model subclassing API](https://www.tensorflow.org/guide/keras/custom_layers_and_models):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h3IKyzTCDNGo"
      },
      "outputs": [],
      "source": [
        "class MyModel(Model):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.conv1 = Conv2D(32, 3, activation='relu')\n",
        "    self.flatten = Flatten()\n",
        "    self.d1 = Dense(128, activation='relu')\n",
        "    self.d2 = Dense(10)\n",
        "\n",
        "  def call(self, x):\n",
        "    x = self.conv1(x)\n",
        "    x = self.flatten(x)\n",
        "    x = self.d1(x)\n",
        "    return self.d2(x)\n",
        "\n",
        "# Create an instance of the model\n",
        "model = MyModel()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uGih-c2LgbJu"
      },
      "source": [
        "Choose an optimizer and loss function for training:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u48C9WQ774n4"
      },
      "outputs": [],
      "source": [
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JB6A1vcigsIe"
      },
      "source": [
        "Select metrics to measure the loss and the accuracy of the model. These metrics accumulate the values over epochs and then print the overall result."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N0MqHFb4F_qn"
      },
      "outputs": [],
      "source": [
        "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
        "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n",
        "\n",
        "test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
        "test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='test_accuracy')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ix4mEL65on-w"
      },
      "source": [
        "Use `tf.GradientTape` to train the model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OZACiVqA8KQV"
      },
      "outputs": [],
      "source": [
        "@tf.function\n",
        "def train_step(images, labels):\n",
        "  with tf.GradientTape() as tape:\n",
        "    # training=True is only needed if there are layers with different\n",
        "    # behavior during training versus inference (e.g. Dropout).\n",
        "    predictions = model(images, training=True)\n",
        "    loss = loss_object(labels, predictions)\n",
        "  gradients = tape.gradient(loss, model.trainable_variables)\n",
        "  optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "\n",
        "  train_loss(loss)\n",
        "  train_accuracy(labels, predictions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z8YT7UmFgpjV"
      },
      "source": [
        "Test the model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xIKdEzHAJGt7"
      },
      "outputs": [],
      "source": [
        "@tf.function\n",
        "def test_step(images, labels):\n",
        "  # training=False is only needed if there are layers with different\n",
        "  # behavior during training versus inference (e.g. Dropout).\n",
        "  predictions = model(images, training=False)\n",
        "  t_loss = loss_object(labels, predictions)\n",
        "\n",
        "  test_loss(t_loss)\n",
        "  test_accuracy(labels, predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i-2pkctU_Ci7",
        "outputId": "2cf836c4-eb2c-46d9-8b12-5f93de54b594",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 0.14, Accuracy: 95.88, Test Loss: 0.06, Test Accuracy: 98.01\n",
            "Epoch 2, Loss: 0.04, Accuracy: 98.70, Test Loss: 0.05, Test Accuracy: 98.33\n",
            "Epoch 3, Loss: 0.02, Accuracy: 99.29, Test Loss: 0.07, Test Accuracy: 98.08\n",
            "Epoch 4, Loss: 0.01, Accuracy: 99.52, Test Loss: 0.06, Test Accuracy: 98.35\n",
            "Epoch 5, Loss: 0.01, Accuracy: 99.69, Test Loss: 0.08, Test Accuracy: 98.07\n"
          ]
        }
      ],
      "source": [
        "EPOCHS = 5\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "  # Reset the metrics at the start of the next epoch\n",
        "  train_loss.reset_state()\n",
        "  train_accuracy.reset_state()\n",
        "  test_loss.reset_state()\n",
        "  test_accuracy.reset_state()\n",
        "\n",
        "  for images, labels in train_ds:\n",
        "    train_step(images, labels)\n",
        "\n",
        "  for test_images, test_labels in test_ds:\n",
        "    test_step(test_images, test_labels)\n",
        "\n",
        "  print(\n",
        "    f'Epoch {epoch + 1}, '\n",
        "    f'Loss: {train_loss.result():0.2f}, '\n",
        "    f'Accuracy: {train_accuracy.result() * 100:0.2f}, '\n",
        "    f'Test Loss: {test_loss.result():0.2f}, '\n",
        "    f'Test Accuracy: {test_accuracy.result() * 100:0.2f}'\n",
        "  )"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bSruP7cwV_l4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qwAXsUezV_od"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2pr_fIMuV_rK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "P1LJUGjQV_u7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import tensorflow as tf\n",
        "print(\"TensorFlow version:\", tf.__version__)\n",
        "\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D\n",
        "from tensorflow.keras import Model\n"
      ],
      "metadata": {
        "id": "3h5aAjtqVq-u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ebe6e47-9b0c-46cb-9c17-b6391e8abebc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow version: 2.15.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## add data augumentation\n",
        "## use imporve CNN\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "from matplotlib import pyplot as plt\n",
        "from keras.models import Sequential\n",
        "from keras.optimizers import Adam, SGD\n",
        "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
        "import tensorflow as tf\n",
        "from keras.models import load_model\n",
        "from keras.layers import GlobalAveragePooling2D, Lambda, Conv2D, MaxPooling2D, Dropout, Dense, Flatten, Activation\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "cifar10 = tf.keras.datasets.cifar10\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "# Hight and width of the images\n",
        "IMAGE_SIZE = 32\n",
        "# 3 channels, Red, Green and Blue\n",
        "CHANNELS = 3\n",
        "# Number of epochs\n",
        "NUM_EPOCH = 350\n",
        "# learning rate\n",
        "LEARN_RATE = 1.0e-4"
      ],
      "metadata": {
        "id": "suO3MqWIbL-j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5aee0d2-f053-480c-f090-62759b5dae23"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170498071/170498071 [==============================] - 3s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, Dropout, GlobalAveragePooling2D, Activation, BatchNormalization\n",
        "\n",
        "def pure_cnn_model():\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(Conv2D(64, (3, 3), padding='same', input_shape=(32, 32, 3)))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Activation('relu'))\n",
        "\n",
        "    model.add(Conv2D(128, (3, 3), padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Activation('relu'))\n",
        "\n",
        "    model.add(Conv2D(128, (3, 3), padding='same', strides=2))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "\n",
        "    model.add(Conv2D(256, (3, 3), padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Activation('relu'))\n",
        "\n",
        "    model.add(Conv2D(256, (3, 3), padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Activation('relu'))\n",
        "\n",
        "    model.add(Conv2D(256, (3, 3), padding='same', strides=2))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "\n",
        "    model.add(Conv2D(256, (3, 3), padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Activation('relu'))\n",
        "\n",
        "    model.add(Conv2D(256, (1, 1), padding='valid'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Activation('relu'))\n",
        "\n",
        "    model.add(Conv2D(10, (1, 1), padding='valid'))\n",
        "\n",
        "    model.add(GlobalAveragePooling2D())\n",
        "    model.add(Activation('softmax'))\n",
        "\n",
        "    model.summary()\n",
        "\n",
        "    return model\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "mIZPKhhwyDH-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    horizontal_flip=True,\n",
        "    zoom_range=0.1,\n",
        "    shear_range=0.1,\n",
        "    fill_mode='nearest'\n",
        ")"
      ],
      "metadata": {
        "id": "qAEI8cH6WTH6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = pure_cnn_model()\n",
        "model.compile(loss='sparse_categorical_crossentropy', # Better loss function for neural networks\n",
        "              optimizer=Adam(lr=0.0001), # Adam optimizer with 1.0e-4 learning rate\n",
        "              metrics = ['accuracy']) # Metrics to be evaluated by the model\n",
        "\n",
        "# model_details = model.fit(datagen.flow(x_train, y_train,\n",
        "#                     batch_size = 32),\n",
        "\n",
        "#                     epochs = 200, # number of iterations\n",
        "#                     validation_data = (x_test, y_test),\n",
        "#                     verbose=1)\n",
        "model_details = model.fit(x_train, y_train,\n",
        "                    batch_size = 128,\n",
        "                    epochs = 200, # number of iterations\n",
        "                    validation_split = 0.15,\n",
        "                    verbose=1)\n",
        "\n",
        "loss, acc = model.evaluate(x_test, y_test)\n",
        "print(acc)"
      ],
      "metadata": {
        "id": "nXJWZd9p6xso",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c47bf59a-7abf-4b65-a541-6beb4324e479"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_18 (Conv2D)          (None, 32, 32, 64)        1792      \n",
            "                                                                 \n",
            " batch_normalization_16 (Ba  (None, 32, 32, 64)        256       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " activation_18 (Activation)  (None, 32, 32, 64)        0         \n",
            "                                                                 \n",
            " conv2d_19 (Conv2D)          (None, 32, 32, 128)       73856     \n",
            "                                                                 \n",
            " batch_normalization_17 (Ba  (None, 32, 32, 128)       512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " activation_19 (Activation)  (None, 32, 32, 128)       0         \n",
            "                                                                 \n",
            " conv2d_20 (Conv2D)          (None, 16, 16, 128)       147584    \n",
            "                                                                 \n",
            " batch_normalization_18 (Ba  (None, 16, 16, 128)       512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " activation_20 (Activation)  (None, 16, 16, 128)       0         \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 16, 16, 128)       0         \n",
            "                                                                 \n",
            " conv2d_21 (Conv2D)          (None, 16, 16, 256)       295168    \n",
            "                                                                 \n",
            " batch_normalization_19 (Ba  (None, 16, 16, 256)       1024      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " activation_21 (Activation)  (None, 16, 16, 256)       0         \n",
            "                                                                 \n",
            " conv2d_22 (Conv2D)          (None, 16, 16, 256)       590080    \n",
            "                                                                 \n",
            " batch_normalization_20 (Ba  (None, 16, 16, 256)       1024      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " activation_22 (Activation)  (None, 16, 16, 256)       0         \n",
            "                                                                 \n",
            " conv2d_23 (Conv2D)          (None, 8, 8, 256)         590080    \n",
            "                                                                 \n",
            " batch_normalization_21 (Ba  (None, 8, 8, 256)         1024      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " activation_23 (Activation)  (None, 8, 8, 256)         0         \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 8, 8, 256)         0         \n",
            "                                                                 \n",
            " conv2d_24 (Conv2D)          (None, 8, 8, 256)         590080    \n",
            "                                                                 \n",
            " batch_normalization_22 (Ba  (None, 8, 8, 256)         1024      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " activation_24 (Activation)  (None, 8, 8, 256)         0         \n",
            "                                                                 \n",
            " conv2d_25 (Conv2D)          (None, 8, 8, 256)         65792     \n",
            "                                                                 \n",
            " batch_normalization_23 (Ba  (None, 8, 8, 256)         1024      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " activation_25 (Activation)  (None, 8, 8, 256)         0         \n",
            "                                                                 \n",
            " conv2d_26 (Conv2D)          (None, 8, 8, 10)          2570      \n",
            "                                                                 \n",
            " global_average_pooling2d_2  (None, 10)                0         \n",
            "  (GlobalAveragePooling2D)                                       \n",
            "                                                                 \n",
            " activation_26 (Activation)  (None, 10)                0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2363402 (9.02 MB)\n",
            "Trainable params: 2360202 (9.00 MB)\n",
            "Non-trainable params: 3200 (12.50 KB)\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "333/333 [==============================] - 42s 101ms/step - loss: 1.3232 - accuracy: 0.5173 - val_loss: 2.3448 - val_accuracy: 0.2640\n",
            "Epoch 2/200\n",
            "333/333 [==============================] - 32s 95ms/step - loss: 0.9452 - accuracy: 0.6627 - val_loss: 1.3041 - val_accuracy: 0.5736\n",
            "Epoch 3/200\n",
            "333/333 [==============================] - 32s 95ms/step - loss: 0.7975 - accuracy: 0.7173 - val_loss: 0.8687 - val_accuracy: 0.6933\n",
            "Epoch 4/200\n",
            "333/333 [==============================] - 32s 96ms/step - loss: 0.6941 - accuracy: 0.7557 - val_loss: 1.7806 - val_accuracy: 0.5265\n",
            "Epoch 5/200\n",
            "333/333 [==============================] - 33s 100ms/step - loss: 0.5978 - accuracy: 0.7921 - val_loss: 1.0922 - val_accuracy: 0.6535\n",
            "Epoch 6/200\n",
            "333/333 [==============================] - 32s 97ms/step - loss: 0.5368 - accuracy: 0.8123 - val_loss: 1.1410 - val_accuracy: 0.6415\n",
            "Epoch 7/200\n",
            "333/333 [==============================] - 32s 97ms/step - loss: 0.4821 - accuracy: 0.8333 - val_loss: 0.7431 - val_accuracy: 0.7452\n",
            "Epoch 8/200\n",
            "333/333 [==============================] - 34s 101ms/step - loss: 0.4482 - accuracy: 0.8437 - val_loss: 0.7643 - val_accuracy: 0.7648\n",
            "Epoch 9/200\n",
            "333/333 [==============================] - 32s 97ms/step - loss: 0.4154 - accuracy: 0.8554 - val_loss: 0.8216 - val_accuracy: 0.7313\n",
            "Epoch 10/200\n",
            "333/333 [==============================] - 34s 101ms/step - loss: 0.3703 - accuracy: 0.8712 - val_loss: 0.7549 - val_accuracy: 0.7448\n",
            "Epoch 11/200\n",
            "333/333 [==============================] - 32s 97ms/step - loss: 0.3367 - accuracy: 0.8814 - val_loss: 0.5355 - val_accuracy: 0.8239\n",
            "Epoch 12/200\n",
            "333/333 [==============================] - 34s 101ms/step - loss: 0.3203 - accuracy: 0.8884 - val_loss: 0.5988 - val_accuracy: 0.7991\n",
            "Epoch 13/200\n",
            "333/333 [==============================] - 32s 97ms/step - loss: 0.2759 - accuracy: 0.9038 - val_loss: 1.0224 - val_accuracy: 0.7152\n",
            "Epoch 14/200\n",
            "333/333 [==============================] - 34s 101ms/step - loss: 0.3020 - accuracy: 0.8949 - val_loss: 0.6566 - val_accuracy: 0.7984\n",
            "Epoch 15/200\n",
            "333/333 [==============================] - 33s 98ms/step - loss: 0.2578 - accuracy: 0.9098 - val_loss: 0.6549 - val_accuracy: 0.8076\n",
            "Epoch 16/200\n",
            "333/333 [==============================] - 34s 101ms/step - loss: 0.2531 - accuracy: 0.9111 - val_loss: 0.4681 - val_accuracy: 0.8472\n",
            "Epoch 17/200\n",
            "333/333 [==============================] - 32s 97ms/step - loss: 0.2174 - accuracy: 0.9238 - val_loss: 0.6956 - val_accuracy: 0.8047\n",
            "Epoch 18/200\n",
            "333/333 [==============================] - 32s 98ms/step - loss: 0.2124 - accuracy: 0.9262 - val_loss: 0.6788 - val_accuracy: 0.8137\n",
            "Epoch 19/200\n",
            "333/333 [==============================] - 34s 102ms/step - loss: 0.1925 - accuracy: 0.9343 - val_loss: 0.4827 - val_accuracy: 0.8505\n",
            "Epoch 20/200\n",
            "333/333 [==============================] - 34s 101ms/step - loss: 0.1821 - accuracy: 0.9356 - val_loss: 0.4693 - val_accuracy: 0.8547\n",
            "Epoch 21/200\n",
            "333/333 [==============================] - 34s 101ms/step - loss: 0.1560 - accuracy: 0.9453 - val_loss: 0.6322 - val_accuracy: 0.8337\n",
            "Epoch 22/200\n",
            "333/333 [==============================] - 32s 98ms/step - loss: 0.1481 - accuracy: 0.9462 - val_loss: 0.5746 - val_accuracy: 0.8411\n",
            "Epoch 23/200\n",
            "333/333 [==============================] - 33s 98ms/step - loss: 0.1218 - accuracy: 0.9568 - val_loss: 0.5510 - val_accuracy: 0.8457\n",
            "Epoch 24/200\n",
            "333/333 [==============================] - 33s 99ms/step - loss: 0.1057 - accuracy: 0.9629 - val_loss: 0.7417 - val_accuracy: 0.8195\n",
            "Epoch 25/200\n",
            "333/333 [==============================] - 33s 98ms/step - loss: 0.1681 - accuracy: 0.9404 - val_loss: 0.5754 - val_accuracy: 0.8425\n",
            "Epoch 26/200\n",
            "333/333 [==============================] - 34s 102ms/step - loss: 0.1057 - accuracy: 0.9631 - val_loss: 0.5266 - val_accuracy: 0.8612\n",
            "Epoch 27/200\n",
            "333/333 [==============================] - 34s 103ms/step - loss: 0.0992 - accuracy: 0.9652 - val_loss: 0.5423 - val_accuracy: 0.8529\n",
            "Epoch 28/200\n",
            "333/333 [==============================] - 34s 102ms/step - loss: 0.1284 - accuracy: 0.9540 - val_loss: 0.6782 - val_accuracy: 0.8360\n",
            "Epoch 29/200\n",
            "333/333 [==============================] - 34s 102ms/step - loss: 0.0762 - accuracy: 0.9732 - val_loss: 0.7166 - val_accuracy: 0.8357\n",
            "Epoch 30/200\n",
            "333/333 [==============================] - 34s 102ms/step - loss: 0.1007 - accuracy: 0.9648 - val_loss: 0.4953 - val_accuracy: 0.8687\n",
            "Epoch 31/200\n",
            "333/333 [==============================] - 33s 99ms/step - loss: 0.0653 - accuracy: 0.9774 - val_loss: 0.7384 - val_accuracy: 0.8339\n",
            "Epoch 32/200\n",
            "333/333 [==============================] - 34s 103ms/step - loss: 0.0962 - accuracy: 0.9659 - val_loss: 0.8491 - val_accuracy: 0.8209\n",
            "Epoch 33/200\n",
            "333/333 [==============================] - 34s 103ms/step - loss: 0.0808 - accuracy: 0.9722 - val_loss: 0.6577 - val_accuracy: 0.8480\n",
            "Epoch 34/200\n",
            "333/333 [==============================] - 34s 102ms/step - loss: 0.1149 - accuracy: 0.9623 - val_loss: 0.6773 - val_accuracy: 0.8373\n",
            "Epoch 35/200\n",
            "333/333 [==============================] - 33s 99ms/step - loss: 0.0870 - accuracy: 0.9710 - val_loss: 0.5717 - val_accuracy: 0.8647\n",
            "Epoch 36/200\n",
            "333/333 [==============================] - 34s 102ms/step - loss: 0.0553 - accuracy: 0.9808 - val_loss: 0.9624 - val_accuracy: 0.7877\n",
            "Epoch 37/200\n",
            "333/333 [==============================] - 34s 103ms/step - loss: 0.1035 - accuracy: 0.9646 - val_loss: 0.5129 - val_accuracy: 0.8715\n",
            "Epoch 38/200\n",
            "333/333 [==============================] - 33s 100ms/step - loss: 0.0993 - accuracy: 0.9663 - val_loss: 0.5045 - val_accuracy: 0.8747\n",
            "Epoch 39/200\n",
            "333/333 [==============================] - 34s 103ms/step - loss: 0.0468 - accuracy: 0.9841 - val_loss: 0.5340 - val_accuracy: 0.8705\n",
            "Epoch 40/200\n",
            "333/333 [==============================] - 34s 103ms/step - loss: 0.0747 - accuracy: 0.9737 - val_loss: 0.5464 - val_accuracy: 0.8667\n",
            "Epoch 41/200\n",
            "333/333 [==============================] - 33s 99ms/step - loss: 0.0745 - accuracy: 0.9737 - val_loss: 0.5233 - val_accuracy: 0.8747\n",
            "Epoch 42/200\n",
            "333/333 [==============================] - 34s 103ms/step - loss: 0.0487 - accuracy: 0.9832 - val_loss: 0.5847 - val_accuracy: 0.8672\n",
            "Epoch 43/200\n",
            "333/333 [==============================] - 34s 103ms/step - loss: 0.0578 - accuracy: 0.9796 - val_loss: 0.5946 - val_accuracy: 0.8645\n",
            "Epoch 44/200\n",
            "333/333 [==============================] - 33s 99ms/step - loss: 0.0386 - accuracy: 0.9866 - val_loss: 0.6137 - val_accuracy: 0.8633\n",
            "Epoch 45/200\n",
            "333/333 [==============================] - 34s 103ms/step - loss: 0.0681 - accuracy: 0.9769 - val_loss: 0.8504 - val_accuracy: 0.8269\n",
            "Epoch 46/200\n",
            "333/333 [==============================] - 34s 103ms/step - loss: 0.0874 - accuracy: 0.9690 - val_loss: 0.5268 - val_accuracy: 0.8740\n",
            "Epoch 47/200\n",
            "333/333 [==============================] - 34s 103ms/step - loss: 0.0695 - accuracy: 0.9769 - val_loss: 0.5731 - val_accuracy: 0.8709\n",
            "Epoch 48/200\n",
            "333/333 [==============================] - 34s 103ms/step - loss: 0.0413 - accuracy: 0.9863 - val_loss: 0.5731 - val_accuracy: 0.8696\n",
            "Epoch 49/200\n",
            "333/333 [==============================] - 34s 102ms/step - loss: 0.0549 - accuracy: 0.9814 - val_loss: 0.6836 - val_accuracy: 0.8524\n",
            "Epoch 50/200\n",
            "333/333 [==============================] - 33s 98ms/step - loss: 0.0569 - accuracy: 0.9804 - val_loss: 0.5991 - val_accuracy: 0.8635\n",
            "Epoch 51/200\n",
            "333/333 [==============================] - 34s 102ms/step - loss: 0.0714 - accuracy: 0.9766 - val_loss: 0.8127 - val_accuracy: 0.8343\n",
            "Epoch 52/200\n",
            "333/333 [==============================] - 34s 102ms/step - loss: 0.0614 - accuracy: 0.9794 - val_loss: 0.5646 - val_accuracy: 0.8719\n",
            "Epoch 53/200\n",
            "333/333 [==============================] - 34s 101ms/step - loss: 0.0571 - accuracy: 0.9811 - val_loss: 0.4692 - val_accuracy: 0.8880\n",
            "Epoch 54/200\n",
            "333/333 [==============================] - 32s 97ms/step - loss: 0.0295 - accuracy: 0.9901 - val_loss: 0.5070 - val_accuracy: 0.8843\n",
            "Epoch 55/200\n",
            "333/333 [==============================] - 32s 97ms/step - loss: 0.0390 - accuracy: 0.9866 - val_loss: 0.6881 - val_accuracy: 0.8547\n",
            "Epoch 56/200\n",
            "333/333 [==============================] - 32s 98ms/step - loss: 0.0307 - accuracy: 0.9892 - val_loss: 0.6203 - val_accuracy: 0.8745\n",
            "Epoch 57/200\n",
            "333/333 [==============================] - 34s 102ms/step - loss: 0.0401 - accuracy: 0.9861 - val_loss: 0.7488 - val_accuracy: 0.8565\n",
            "Epoch 58/200\n",
            "333/333 [==============================] - 32s 98ms/step - loss: 0.0354 - accuracy: 0.9874 - val_loss: 0.5568 - val_accuracy: 0.8795\n",
            "Epoch 59/200\n",
            "333/333 [==============================] - 34s 101ms/step - loss: 0.0338 - accuracy: 0.9880 - val_loss: 0.7159 - val_accuracy: 0.8577\n",
            "Epoch 60/200\n",
            "333/333 [==============================] - 32s 98ms/step - loss: 0.0700 - accuracy: 0.9764 - val_loss: 0.6633 - val_accuracy: 0.8601\n",
            "Epoch 61/200\n",
            "333/333 [==============================] - 34s 101ms/step - loss: 0.0754 - accuracy: 0.9757 - val_loss: 0.6212 - val_accuracy: 0.8680\n",
            "Epoch 62/200\n",
            "333/333 [==============================] - 34s 101ms/step - loss: 0.0312 - accuracy: 0.9894 - val_loss: 0.5324 - val_accuracy: 0.8835\n",
            "Epoch 63/200\n",
            "333/333 [==============================] - 32s 97ms/step - loss: 0.0285 - accuracy: 0.9907 - val_loss: 0.5618 - val_accuracy: 0.8837\n",
            "Epoch 64/200\n",
            "333/333 [==============================] - 33s 98ms/step - loss: 0.0277 - accuracy: 0.9901 - val_loss: 0.9647 - val_accuracy: 0.8116\n",
            "Epoch 65/200\n",
            "333/333 [==============================] - 34s 102ms/step - loss: 0.0924 - accuracy: 0.9701 - val_loss: 0.5738 - val_accuracy: 0.8749\n",
            "Epoch 66/200\n",
            "333/333 [==============================] - 32s 97ms/step - loss: 0.0641 - accuracy: 0.9783 - val_loss: 0.6231 - val_accuracy: 0.8691\n",
            "Epoch 67/200\n",
            "333/333 [==============================] - 32s 97ms/step - loss: 0.0327 - accuracy: 0.9889 - val_loss: 0.5541 - val_accuracy: 0.8821\n",
            "Epoch 68/200\n",
            "333/333 [==============================] - 34s 102ms/step - loss: 0.0269 - accuracy: 0.9911 - val_loss: 0.5221 - val_accuracy: 0.8859\n",
            "Epoch 69/200\n",
            "333/333 [==============================] - 34s 101ms/step - loss: 0.0251 - accuracy: 0.9914 - val_loss: 0.5643 - val_accuracy: 0.8797\n",
            "Epoch 70/200\n",
            "333/333 [==============================] - 34s 101ms/step - loss: 0.0224 - accuracy: 0.9924 - val_loss: 0.7685 - val_accuracy: 0.8472\n",
            "Epoch 71/200\n",
            "333/333 [==============================] - 32s 98ms/step - loss: 0.0755 - accuracy: 0.9761 - val_loss: 0.5434 - val_accuracy: 0.8819\n",
            "Epoch 72/200\n",
            "333/333 [==============================] - 34s 102ms/step - loss: 0.0289 - accuracy: 0.9898 - val_loss: 0.5620 - val_accuracy: 0.8745\n",
            "Epoch 73/200\n",
            "333/333 [==============================] - 32s 97ms/step - loss: 0.0535 - accuracy: 0.9821 - val_loss: 0.6088 - val_accuracy: 0.8712\n",
            "Epoch 74/200\n",
            "333/333 [==============================] - 34s 101ms/step - loss: 0.0235 - accuracy: 0.9916 - val_loss: 0.5778 - val_accuracy: 0.8835\n",
            "Epoch 75/200\n",
            "333/333 [==============================] - 32s 97ms/step - loss: 0.0254 - accuracy: 0.9911 - val_loss: 0.7769 - val_accuracy: 0.8536\n",
            "Epoch 76/200\n",
            "333/333 [==============================] - 32s 97ms/step - loss: 0.0408 - accuracy: 0.9867 - val_loss: 0.5678 - val_accuracy: 0.8763\n",
            "Epoch 77/200\n",
            "333/333 [==============================] - 34s 101ms/step - loss: 0.0234 - accuracy: 0.9916 - val_loss: 0.7361 - val_accuracy: 0.8555\n",
            "Epoch 78/200\n",
            "333/333 [==============================] - 32s 97ms/step - loss: 0.0602 - accuracy: 0.9794 - val_loss: 0.7457 - val_accuracy: 0.8456\n",
            "Epoch 79/200\n",
            "333/333 [==============================] - 32s 97ms/step - loss: 0.0555 - accuracy: 0.9802 - val_loss: 0.6930 - val_accuracy: 0.8656\n",
            "Epoch 80/200\n",
            "333/333 [==============================] - 32s 98ms/step - loss: 0.0527 - accuracy: 0.9830 - val_loss: 0.5636 - val_accuracy: 0.8796\n",
            "Epoch 81/200\n",
            "333/333 [==============================] - 32s 97ms/step - loss: 0.0262 - accuracy: 0.9907 - val_loss: 0.5874 - val_accuracy: 0.8827\n",
            "Epoch 82/200\n",
            "333/333 [==============================] - 33s 98ms/step - loss: 0.0291 - accuracy: 0.9905 - val_loss: 0.6201 - val_accuracy: 0.8724\n",
            "Epoch 83/200\n",
            "333/333 [==============================] - 34s 102ms/step - loss: 0.0204 - accuracy: 0.9927 - val_loss: 0.7601 - val_accuracy: 0.8576\n",
            "Epoch 84/200\n",
            "333/333 [==============================] - 34s 101ms/step - loss: 0.0461 - accuracy: 0.9843 - val_loss: 0.5371 - val_accuracy: 0.8843\n",
            "Epoch 85/200\n",
            "333/333 [==============================] - 32s 97ms/step - loss: 0.0259 - accuracy: 0.9914 - val_loss: 0.5981 - val_accuracy: 0.8763\n",
            "Epoch 86/200\n",
            "333/333 [==============================] - 34s 101ms/step - loss: 0.0219 - accuracy: 0.9925 - val_loss: 0.6358 - val_accuracy: 0.8697\n",
            "Epoch 87/200\n",
            "333/333 [==============================] - 33s 98ms/step - loss: 0.0567 - accuracy: 0.9816 - val_loss: 0.5688 - val_accuracy: 0.8836\n",
            "Epoch 88/200\n",
            "333/333 [==============================] - 32s 97ms/step - loss: 0.0393 - accuracy: 0.9868 - val_loss: 0.7574 - val_accuracy: 0.8611\n",
            "Epoch 89/200\n",
            "333/333 [==============================] - 34s 102ms/step - loss: 0.0433 - accuracy: 0.9858 - val_loss: 0.5891 - val_accuracy: 0.8819\n",
            "Epoch 90/200\n",
            "333/333 [==============================] - 34s 101ms/step - loss: 0.0448 - accuracy: 0.9840 - val_loss: 0.5732 - val_accuracy: 0.8829\n",
            "Epoch 91/200\n",
            "333/333 [==============================] - 34s 101ms/step - loss: 0.0193 - accuracy: 0.9934 - val_loss: 0.5547 - val_accuracy: 0.8896\n",
            "Epoch 92/200\n",
            "333/333 [==============================] - 34s 101ms/step - loss: 0.0169 - accuracy: 0.9942 - val_loss: 0.6729 - val_accuracy: 0.8677\n",
            "Epoch 93/200\n",
            "333/333 [==============================] - 34s 101ms/step - loss: 0.0206 - accuracy: 0.9931 - val_loss: 0.5829 - val_accuracy: 0.8884\n",
            "Epoch 94/200\n",
            "333/333 [==============================] - 32s 97ms/step - loss: 0.0167 - accuracy: 0.9944 - val_loss: 0.6607 - val_accuracy: 0.8703\n",
            "Epoch 95/200\n",
            "333/333 [==============================] - 32s 98ms/step - loss: 0.0309 - accuracy: 0.9894 - val_loss: 0.6067 - val_accuracy: 0.8864\n",
            "Epoch 96/200\n",
            "333/333 [==============================] - 34s 101ms/step - loss: 0.0199 - accuracy: 0.9927 - val_loss: 0.6381 - val_accuracy: 0.8735\n",
            "Epoch 97/200\n",
            "333/333 [==============================] - 32s 97ms/step - loss: 0.0297 - accuracy: 0.9908 - val_loss: 0.5760 - val_accuracy: 0.8831\n",
            "Epoch 98/200\n",
            "333/333 [==============================] - 34s 101ms/step - loss: 0.0207 - accuracy: 0.9934 - val_loss: 0.6482 - val_accuracy: 0.8757\n",
            "Epoch 99/200\n",
            "333/333 [==============================] - 34s 101ms/step - loss: 0.0197 - accuracy: 0.9928 - val_loss: 0.6104 - val_accuracy: 0.8817\n",
            "Epoch 100/200\n",
            "333/333 [==============================] - 32s 97ms/step - loss: 0.0212 - accuracy: 0.9928 - val_loss: 0.6882 - val_accuracy: 0.8641\n",
            "Epoch 101/200\n",
            "333/333 [==============================] - 34s 101ms/step - loss: 0.0237 - accuracy: 0.9920 - val_loss: 0.6811 - val_accuracy: 0.8733\n",
            "Epoch 102/200\n",
            "333/333 [==============================] - 33s 98ms/step - loss: 0.0247 - accuracy: 0.9917 - val_loss: 0.7632 - val_accuracy: 0.8653\n",
            "Epoch 103/200\n",
            "333/333 [==============================] - 34s 102ms/step - loss: 0.0203 - accuracy: 0.9927 - val_loss: 0.7174 - val_accuracy: 0.8693\n",
            "Epoch 104/200\n",
            "333/333 [==============================] - 32s 97ms/step - loss: 0.0221 - accuracy: 0.9928 - val_loss: 1.0093 - val_accuracy: 0.8248\n",
            "Epoch 105/200\n",
            "333/333 [==============================] - 32s 98ms/step - loss: 0.0608 - accuracy: 0.9806 - val_loss: 0.6498 - val_accuracy: 0.8723\n",
            "Epoch 106/200\n",
            "333/333 [==============================] - 33s 98ms/step - loss: 0.0240 - accuracy: 0.9920 - val_loss: 0.6293 - val_accuracy: 0.8763\n",
            "Epoch 107/200\n",
            "333/333 [==============================] - 33s 98ms/step - loss: 0.0450 - accuracy: 0.9848 - val_loss: 0.5975 - val_accuracy: 0.8801\n",
            "Epoch 108/200\n",
            "333/333 [==============================] - 34s 102ms/step - loss: 0.0179 - accuracy: 0.9942 - val_loss: 0.5812 - val_accuracy: 0.8851\n",
            "Epoch 109/200\n",
            "333/333 [==============================] - 33s 98ms/step - loss: 0.0157 - accuracy: 0.9945 - val_loss: 0.6043 - val_accuracy: 0.8860\n",
            "Epoch 110/200\n",
            "333/333 [==============================] - 33s 98ms/step - loss: 0.0373 - accuracy: 0.9875 - val_loss: 0.6622 - val_accuracy: 0.8781\n",
            "Epoch 111/200\n",
            "333/333 [==============================] - 34s 102ms/step - loss: 0.0394 - accuracy: 0.9875 - val_loss: 0.6291 - val_accuracy: 0.8736\n",
            "Epoch 112/200\n",
            "333/333 [==============================] - 34s 102ms/step - loss: 0.0231 - accuracy: 0.9920 - val_loss: 0.5885 - val_accuracy: 0.8868\n",
            "Epoch 113/200\n",
            "333/333 [==============================] - 33s 98ms/step - loss: 0.0143 - accuracy: 0.9952 - val_loss: 0.5750 - val_accuracy: 0.8896\n",
            "Epoch 114/200\n",
            "333/333 [==============================] - 33s 98ms/step - loss: 0.0160 - accuracy: 0.9948 - val_loss: 0.6218 - val_accuracy: 0.8825\n",
            "Epoch 115/200\n",
            "333/333 [==============================] - 33s 98ms/step - loss: 0.0273 - accuracy: 0.9906 - val_loss: 0.6765 - val_accuracy: 0.8739\n",
            "Epoch 116/200\n",
            "333/333 [==============================] - 34s 102ms/step - loss: 0.0150 - accuracy: 0.9952 - val_loss: 0.6787 - val_accuracy: 0.8793\n",
            "Epoch 117/200\n",
            "333/333 [==============================] - 33s 98ms/step - loss: 0.0148 - accuracy: 0.9949 - val_loss: 0.6335 - val_accuracy: 0.8864\n",
            "Epoch 118/200\n",
            "333/333 [==============================] - 33s 98ms/step - loss: 0.0174 - accuracy: 0.9944 - val_loss: 0.6446 - val_accuracy: 0.8799\n",
            "Epoch 119/200\n",
            "333/333 [==============================] - 34s 102ms/step - loss: 0.0358 - accuracy: 0.9878 - val_loss: 0.7008 - val_accuracy: 0.8680\n",
            "Epoch 120/200\n",
            "333/333 [==============================] - 34s 102ms/step - loss: 0.0516 - accuracy: 0.9836 - val_loss: 0.6039 - val_accuracy: 0.8788\n",
            "Epoch 121/200\n",
            "333/333 [==============================] - 34s 102ms/step - loss: 0.0442 - accuracy: 0.9857 - val_loss: 0.6574 - val_accuracy: 0.8744\n",
            "Epoch 122/200\n",
            "333/333 [==============================] - 33s 99ms/step - loss: 0.0193 - accuracy: 0.9937 - val_loss: 0.6676 - val_accuracy: 0.8788\n",
            "Epoch 123/200\n",
            "333/333 [==============================] - 33s 98ms/step - loss: 0.0451 - accuracy: 0.9856 - val_loss: 0.5624 - val_accuracy: 0.8840\n",
            "Epoch 124/200\n",
            "333/333 [==============================] - 33s 98ms/step - loss: 0.0163 - accuracy: 0.9942 - val_loss: 0.5870 - val_accuracy: 0.8883\n",
            "Epoch 125/200\n",
            "333/333 [==============================] - 33s 98ms/step - loss: 0.0117 - accuracy: 0.9961 - val_loss: 0.5963 - val_accuracy: 0.8884\n",
            "Epoch 126/200\n",
            "333/333 [==============================] - 34s 102ms/step - loss: 0.0136 - accuracy: 0.9955 - val_loss: 0.6218 - val_accuracy: 0.8876\n",
            "Epoch 127/200\n",
            "333/333 [==============================] - 33s 98ms/step - loss: 0.0128 - accuracy: 0.9957 - val_loss: 0.6694 - val_accuracy: 0.8815\n",
            "Epoch 128/200\n",
            "333/333 [==============================] - 34s 102ms/step - loss: 0.0151 - accuracy: 0.9951 - val_loss: 0.6166 - val_accuracy: 0.8836\n",
            "Epoch 129/200\n",
            "333/333 [==============================] - 33s 98ms/step - loss: 0.0172 - accuracy: 0.9944 - val_loss: 0.6471 - val_accuracy: 0.8864\n",
            "Epoch 130/200\n",
            "333/333 [==============================] - 33s 98ms/step - loss: 0.0517 - accuracy: 0.9835 - val_loss: 0.6966 - val_accuracy: 0.8709\n",
            "Epoch 131/200\n",
            "333/333 [==============================] - 34s 102ms/step - loss: 0.0249 - accuracy: 0.9917 - val_loss: 0.6351 - val_accuracy: 0.8744\n",
            "Epoch 132/200\n",
            "333/333 [==============================] - 34s 103ms/step - loss: 0.0256 - accuracy: 0.9916 - val_loss: 0.6467 - val_accuracy: 0.8813\n",
            "Epoch 133/200\n",
            "333/333 [==============================] - 33s 99ms/step - loss: 0.0347 - accuracy: 0.9884 - val_loss: 0.6260 - val_accuracy: 0.8831\n",
            "Epoch 134/200\n",
            "333/333 [==============================] - 33s 98ms/step - loss: 0.0292 - accuracy: 0.9909 - val_loss: 0.5933 - val_accuracy: 0.8833\n",
            "Epoch 135/200\n",
            "333/333 [==============================] - 33s 99ms/step - loss: 0.0149 - accuracy: 0.9950 - val_loss: 0.5768 - val_accuracy: 0.8888\n",
            "Epoch 136/200\n",
            "333/333 [==============================] - 34s 102ms/step - loss: 0.0120 - accuracy: 0.9960 - val_loss: 0.6331 - val_accuracy: 0.8825\n",
            "Epoch 137/200\n",
            "333/333 [==============================] - 34s 103ms/step - loss: 0.0173 - accuracy: 0.9946 - val_loss: 0.6656 - val_accuracy: 0.8744\n",
            "Epoch 138/200\n",
            "333/333 [==============================] - 33s 99ms/step - loss: 0.0128 - accuracy: 0.9959 - val_loss: 0.6670 - val_accuracy: 0.8801\n",
            "Epoch 139/200\n",
            "333/333 [==============================] - 33s 99ms/step - loss: 0.0124 - accuracy: 0.9958 - val_loss: 0.6189 - val_accuracy: 0.8864\n",
            "Epoch 140/200\n",
            "333/333 [==============================] - 34s 103ms/step - loss: 0.0139 - accuracy: 0.9954 - val_loss: 0.6184 - val_accuracy: 0.8891\n",
            "Epoch 141/200\n",
            "333/333 [==============================] - 34s 103ms/step - loss: 0.0148 - accuracy: 0.9947 - val_loss: 0.7555 - val_accuracy: 0.8709\n",
            "Epoch 142/200\n",
            "333/333 [==============================] - 33s 99ms/step - loss: 0.0292 - accuracy: 0.9905 - val_loss: 0.6500 - val_accuracy: 0.8847\n",
            "Epoch 143/200\n",
            "333/333 [==============================] - 33s 99ms/step - loss: 0.0175 - accuracy: 0.9940 - val_loss: 0.6527 - val_accuracy: 0.8819\n",
            "Epoch 144/200\n",
            "333/333 [==============================] - 34s 103ms/step - loss: 0.0164 - accuracy: 0.9941 - val_loss: 0.6568 - val_accuracy: 0.8820\n",
            "Epoch 145/200\n",
            "333/333 [==============================] - 34s 103ms/step - loss: 0.0343 - accuracy: 0.9884 - val_loss: 0.7376 - val_accuracy: 0.8693\n",
            "Epoch 146/200\n",
            "333/333 [==============================] - 34s 103ms/step - loss: 0.0361 - accuracy: 0.9877 - val_loss: 0.7260 - val_accuracy: 0.8660\n",
            "Epoch 147/200\n",
            "333/333 [==============================] - 33s 99ms/step - loss: 0.0292 - accuracy: 0.9905 - val_loss: 0.6243 - val_accuracy: 0.8801\n",
            "Epoch 148/200\n",
            "333/333 [==============================] - 34s 103ms/step - loss: 0.0389 - accuracy: 0.9878 - val_loss: 0.6431 - val_accuracy: 0.8832\n",
            "Epoch 149/200\n",
            "333/333 [==============================] - 34s 103ms/step - loss: 0.0147 - accuracy: 0.9950 - val_loss: 0.6706 - val_accuracy: 0.8796\n",
            "Epoch 150/200\n",
            "333/333 [==============================] - 34s 103ms/step - loss: 0.0105 - accuracy: 0.9965 - val_loss: 0.6000 - val_accuracy: 0.8916\n",
            "Epoch 151/200\n",
            " 82/333 [======>.......................] - ETA: 23s - loss: 0.0096 - accuracy: 0.9968"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss, acc = model.evaluate(x_test, y_test)"
      ],
      "metadata": {
        "id": "Ggg0hTYv_jZq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "from tensorflow.keras import layers, Sequential, regularizers\n",
        "from tensorflow.keras.layers import Conv2D, BatchNormalization, Activation, MaxPool2D, Dropout, Flatten, Dense\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow import keras\n",
        "import tensorflow.keras.preprocessing.image as image"
      ],
      "metadata": {
        "id": "Zq_HOm9H_jcc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cifar10 = tf.keras.datasets.cifar10\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "x_valid,x_train=x_train[:3000],x_train[3000:]\n",
        "y_valid,y_train=y_train[:3000],y_train[3000:]\n"
      ],
      "metadata": {
        "id": "IhvBslzT_jfJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ResnetBlock(Model):\n",
        "\n",
        "    def __init__(self, filters, strides=1, residual_path=False):\n",
        "        super(ResnetBlock, self).__init__()\n",
        "        self.filters = filters\n",
        "        self.strides = strides\n",
        "        self.residual_path = residual_path\n",
        "\n",
        "        self.c1 = Conv2D(filters, (3, 3), strides=strides, padding='same',\n",
        "                         kernel_regularizer=regularizers.l2(5e-5), use_bias=False, kernel_initializer='glorot_normal')\n",
        "        self.b1 = BatchNormalization()\n",
        "        self.a1 = Activation('relu')\n",
        "\n",
        "        self.c2 = Conv2D(filters, (3, 3), strides=1, padding='same',\n",
        "                          kernel_regularizer=regularizers.l2(5e-5), use_bias=False, kernel_initializer='glorot_normal')\n",
        "        self.b2 = BatchNormalization()\n",
        "\n",
        "\n",
        "        if residual_path:\n",
        "            self.down_c1 = Conv2D(filters, (1, 1), strides=strides, padding='same',\n",
        "                                  kernel_regularizer=regularizers.l2(5e-5), use_bias=False, kernel_initializer='glorot_normal')\n",
        "            self.down_b1 = BatchNormalization()\n",
        "\n",
        "        self.a2 = Activation('relu')\n",
        "\n",
        "    def call(self, inputs):\n",
        "        residual = inputs\n",
        "\n",
        "        x = self.c1(inputs)\n",
        "        x = self.b1(x)\n",
        "        x = self.a1(x)\n",
        "\n",
        "        x = self.c2(x)\n",
        "        y = self.b2(x)\n",
        "\n",
        "        if self.residual_path:\n",
        "            residual = self.down_c1(inputs)\n",
        "            residual = self.down_b1(residual)\n",
        "\n",
        "        out = self.a2(y + residual)\n",
        "        return out\n",
        "\n",
        "\n",
        "class ResNet18(Model):\n",
        "\n",
        "    def __init__(self, block_list, initial_filters=64):\n",
        "        super(ResNet18, self).__init__()\n",
        "        self.num_blocks = len(block_list)\n",
        "        self.block_list = block_list\n",
        "        self.out_filters = initial_filters\n",
        "        self.c1 = Conv2D(self.out_filters, (3, 3), strides=1, padding='same', use_bias=False)\n",
        "        self.b1 = BatchNormalization()\n",
        "        self.a1 = Activation('relu')\n",
        "        self.blocks = tf.keras.models.Sequential()\n",
        "\n",
        "        for block_id in range(len(block_list)):\n",
        "            for layer_id in range(block_list[block_id]):\n",
        "\n",
        "                if block_id != 0 and layer_id == 0:\n",
        "                    block = ResnetBlock(self.out_filters, strides=2, residual_path=True)\n",
        "                else:\n",
        "                    block = ResnetBlock(self.out_filters, residual_path=False)\n",
        "                self.blocks.add(block)\n",
        "            self.out_filters *= 2\n",
        "        self.p1 = tf.keras.layers.GlobalAveragePooling2D()\n",
        "        self.f1 = tf.keras.layers.Dense(10, activation='softmax', kernel_regularizer=tf.keras.regularizers.l2())\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x = self.c1(inputs)\n",
        "        x = self.b1(x)\n",
        "        x = self.a1(x)\n",
        "        x = self.blocks(x)\n",
        "        x = self.p1(x)\n",
        "        y = self.f1(x)\n",
        "        return y\n",
        "\n",
        "\n",
        "model = ResNet18([2, 2, 2, 2])\n",
        "save_path = 'resnet18.h5'\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "        loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
        "        metrics=['sparse_categorical_accuracy'])\n",
        "\n",
        "\n",
        "print('-------------load the model-----------------')\n",
        "\n",
        "history = model.fit(datagen.flow(x_train, y_train, batch_size=32), epochs=100, validation_data=(x_valid, y_valid), validation_freq=1)\n",
        "    #history = model.fit(x_train, y_train, batch_size=32, epochs=10, validation_data=(x_valid, y_valid), validation_freq=1,\n",
        "                #   callbacks=[cp_callback])\n",
        "model.summary()\n",
        "loss, acc = model.evaluate(x_test, y_test)\n",
        "print(acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bG05LX2c_jhf",
        "outputId": "c4811a53-d74e-464d-8004-acda501f3f14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------load the model-----------------\n",
            "Epoch 1/100\n",
            "1469/1469 [==============================] - 118s 46ms/step - loss: 1.8440 - sparse_categorical_accuracy: 0.4515 - val_loss: 1.4358 - val_sparse_categorical_accuracy: 0.5680\n",
            "Epoch 2/100\n",
            "1469/1469 [==============================] - 65s 45ms/step - loss: 1.3456 - sparse_categorical_accuracy: 0.6128 - val_loss: 2.1030 - val_sparse_categorical_accuracy: 0.4940\n",
            "Epoch 3/100\n",
            "1469/1469 [==============================] - 64s 44ms/step - loss: 1.1859 - sparse_categorical_accuracy: 0.6771 - val_loss: 1.3804 - val_sparse_categorical_accuracy: 0.6283\n",
            "Epoch 4/100\n",
            "1469/1469 [==============================] - 65s 44ms/step - loss: 1.1053 - sparse_categorical_accuracy: 0.7165 - val_loss: 1.3322 - val_sparse_categorical_accuracy: 0.6707\n",
            "Epoch 5/100\n",
            "1469/1469 [==============================] - 65s 44ms/step - loss: 1.0627 - sparse_categorical_accuracy: 0.7376 - val_loss: 1.2633 - val_sparse_categorical_accuracy: 0.6773\n",
            "Epoch 6/100\n",
            "1469/1469 [==============================] - 65s 44ms/step - loss: 1.0192 - sparse_categorical_accuracy: 0.7593 - val_loss: 1.0781 - val_sparse_categorical_accuracy: 0.7510\n",
            "Epoch 7/100\n",
            "1469/1469 [==============================] - 64s 44ms/step - loss: 0.9718 - sparse_categorical_accuracy: 0.7773 - val_loss: 1.2629 - val_sparse_categorical_accuracy: 0.7060\n",
            "Epoch 8/100\n",
            "1469/1469 [==============================] - 66s 45ms/step - loss: 0.9334 - sparse_categorical_accuracy: 0.7911 - val_loss: 1.0725 - val_sparse_categorical_accuracy: 0.7530\n",
            "Epoch 9/100\n",
            "1469/1469 [==============================] - 64s 44ms/step - loss: 0.9017 - sparse_categorical_accuracy: 0.8011 - val_loss: 1.0374 - val_sparse_categorical_accuracy: 0.7697\n",
            "Epoch 10/100\n",
            "1469/1469 [==============================] - 64s 44ms/step - loss: 0.8742 - sparse_categorical_accuracy: 0.8103 - val_loss: 1.2796 - val_sparse_categorical_accuracy: 0.7223\n",
            "Epoch 11/100\n",
            "1469/1469 [==============================] - 65s 44ms/step - loss: 0.8511 - sparse_categorical_accuracy: 0.8177 - val_loss: 0.8721 - val_sparse_categorical_accuracy: 0.8253\n",
            "Epoch 12/100\n",
            "1469/1469 [==============================] - 64s 44ms/step - loss: 0.8258 - sparse_categorical_accuracy: 0.8276 - val_loss: 0.9312 - val_sparse_categorical_accuracy: 0.7927\n",
            "Epoch 13/100\n",
            "1469/1469 [==============================] - 64s 44ms/step - loss: 0.8053 - sparse_categorical_accuracy: 0.8342 - val_loss: 0.8459 - val_sparse_categorical_accuracy: 0.8207\n",
            "Epoch 14/100\n",
            "1469/1469 [==============================] - 64s 44ms/step - loss: 0.7952 - sparse_categorical_accuracy: 0.8355 - val_loss: 0.7498 - val_sparse_categorical_accuracy: 0.8523\n",
            "Epoch 15/100\n",
            "1469/1469 [==============================] - 64s 43ms/step - loss: 0.7816 - sparse_categorical_accuracy: 0.8409 - val_loss: 0.7949 - val_sparse_categorical_accuracy: 0.8393\n",
            "Epoch 16/100\n",
            "1469/1469 [==============================] - 65s 44ms/step - loss: 0.7619 - sparse_categorical_accuracy: 0.8459 - val_loss: 0.8220 - val_sparse_categorical_accuracy: 0.8227\n",
            "Epoch 17/100\n",
            "1469/1469 [==============================] - 64s 44ms/step - loss: 0.7501 - sparse_categorical_accuracy: 0.8506 - val_loss: 0.6842 - val_sparse_categorical_accuracy: 0.8737\n",
            "Epoch 18/100\n",
            "1469/1469 [==============================] - 64s 44ms/step - loss: 0.7372 - sparse_categorical_accuracy: 0.8535 - val_loss: 0.8307 - val_sparse_categorical_accuracy: 0.8257\n",
            "Epoch 19/100\n",
            "1469/1469 [==============================] - 65s 44ms/step - loss: 0.7189 - sparse_categorical_accuracy: 0.8593 - val_loss: 0.7658 - val_sparse_categorical_accuracy: 0.8403\n",
            "Epoch 20/100\n",
            "1469/1469 [==============================] - 64s 43ms/step - loss: 0.7242 - sparse_categorical_accuracy: 0.8573 - val_loss: 0.7477 - val_sparse_categorical_accuracy: 0.8490\n",
            "Epoch 21/100\n",
            "1469/1469 [==============================] - 64s 43ms/step - loss: 0.7121 - sparse_categorical_accuracy: 0.8585 - val_loss: 0.8002 - val_sparse_categorical_accuracy: 0.8340\n",
            "Epoch 22/100\n",
            "1469/1469 [==============================] - 64s 44ms/step - loss: 0.7008 - sparse_categorical_accuracy: 0.8634 - val_loss: 0.6661 - val_sparse_categorical_accuracy: 0.8790\n",
            "Epoch 23/100\n",
            "1469/1469 [==============================] - 64s 43ms/step - loss: 0.6884 - sparse_categorical_accuracy: 0.8673 - val_loss: 1.0124 - val_sparse_categorical_accuracy: 0.7750\n",
            "Epoch 24/100\n",
            "1469/1469 [==============================] - 64s 43ms/step - loss: 0.6860 - sparse_categorical_accuracy: 0.8659 - val_loss: 0.6682 - val_sparse_categorical_accuracy: 0.8717\n",
            "Epoch 25/100\n",
            "1469/1469 [==============================] - 64s 43ms/step - loss: 0.6742 - sparse_categorical_accuracy: 0.8717 - val_loss: 0.6421 - val_sparse_categorical_accuracy: 0.8843\n",
            "Epoch 26/100\n",
            "1469/1469 [==============================] - 64s 44ms/step - loss: 0.6713 - sparse_categorical_accuracy: 0.8707 - val_loss: 0.6540 - val_sparse_categorical_accuracy: 0.8760\n",
            "Epoch 27/100\n",
            "1469/1469 [==============================] - 64s 43ms/step - loss: 0.6664 - sparse_categorical_accuracy: 0.8721 - val_loss: 0.6188 - val_sparse_categorical_accuracy: 0.8917\n",
            "Epoch 28/100\n",
            "1469/1469 [==============================] - 63s 43ms/step - loss: 0.6603 - sparse_categorical_accuracy: 0.8740 - val_loss: 0.7383 - val_sparse_categorical_accuracy: 0.8450\n",
            "Epoch 29/100\n",
            "1469/1469 [==============================] - 64s 43ms/step - loss: 0.6562 - sparse_categorical_accuracy: 0.8748 - val_loss: 0.7339 - val_sparse_categorical_accuracy: 0.8593\n",
            "Epoch 30/100\n",
            "1469/1469 [==============================] - 64s 43ms/step - loss: 0.6563 - sparse_categorical_accuracy: 0.8750 - val_loss: 0.7903 - val_sparse_categorical_accuracy: 0.8260\n",
            "Epoch 31/100\n",
            "1469/1469 [==============================] - 64s 44ms/step - loss: 0.6452 - sparse_categorical_accuracy: 0.8774 - val_loss: 0.6721 - val_sparse_categorical_accuracy: 0.8593\n",
            "Epoch 32/100\n",
            "1469/1469 [==============================] - 64s 44ms/step - loss: 0.6402 - sparse_categorical_accuracy: 0.8794 - val_loss: 0.7000 - val_sparse_categorical_accuracy: 0.8610\n",
            "Epoch 33/100\n",
            "1469/1469 [==============================] - 64s 43ms/step - loss: 0.6391 - sparse_categorical_accuracy: 0.8790 - val_loss: 0.7103 - val_sparse_categorical_accuracy: 0.8573\n",
            "Epoch 34/100\n",
            "1469/1469 [==============================] - 64s 43ms/step - loss: 0.6332 - sparse_categorical_accuracy: 0.8805 - val_loss: 0.6116 - val_sparse_categorical_accuracy: 0.8877\n",
            "Epoch 35/100\n",
            "1469/1469 [==============================] - 64s 44ms/step - loss: 0.6234 - sparse_categorical_accuracy: 0.8865 - val_loss: 0.6930 - val_sparse_categorical_accuracy: 0.8697\n",
            "Epoch 36/100\n",
            "1469/1469 [==============================] - 63s 43ms/step - loss: 0.6278 - sparse_categorical_accuracy: 0.8850 - val_loss: 0.7247 - val_sparse_categorical_accuracy: 0.8547\n",
            "Epoch 37/100\n",
            "1469/1469 [==============================] - 64s 43ms/step - loss: 0.6218 - sparse_categorical_accuracy: 0.8852 - val_loss: 0.6348 - val_sparse_categorical_accuracy: 0.8797\n",
            "Epoch 38/100\n",
            "1469/1469 [==============================] - 65s 44ms/step - loss: 0.6186 - sparse_categorical_accuracy: 0.8847 - val_loss: 0.6891 - val_sparse_categorical_accuracy: 0.8670\n",
            "Epoch 39/100\n",
            "1469/1469 [==============================] - 64s 44ms/step - loss: 0.6150 - sparse_categorical_accuracy: 0.8856 - val_loss: 0.7570 - val_sparse_categorical_accuracy: 0.8483\n",
            "Epoch 40/100\n",
            "1469/1469 [==============================] - 64s 43ms/step - loss: 0.6131 - sparse_categorical_accuracy: 0.8879 - val_loss: 0.6235 - val_sparse_categorical_accuracy: 0.8843\n",
            "Epoch 41/100\n",
            "1469/1469 [==============================] - 65s 44ms/step - loss: 0.6101 - sparse_categorical_accuracy: 0.8886 - val_loss: 0.6385 - val_sparse_categorical_accuracy: 0.8823\n",
            "Epoch 42/100\n",
            "1469/1469 [==============================] - 64s 44ms/step - loss: 0.6102 - sparse_categorical_accuracy: 0.8870 - val_loss: 0.7342 - val_sparse_categorical_accuracy: 0.8533\n",
            "Epoch 43/100\n",
            "1469/1469 [==============================] - 63s 43ms/step - loss: 0.6054 - sparse_categorical_accuracy: 0.8887 - val_loss: 0.6075 - val_sparse_categorical_accuracy: 0.8910\n",
            "Epoch 44/100\n",
            "1469/1469 [==============================] - 64s 44ms/step - loss: 0.6026 - sparse_categorical_accuracy: 0.8892 - val_loss: 0.6194 - val_sparse_categorical_accuracy: 0.8913\n",
            "Epoch 45/100\n",
            "1469/1469 [==============================] - 64s 43ms/step - loss: 0.5977 - sparse_categorical_accuracy: 0.8902 - val_loss: 0.6866 - val_sparse_categorical_accuracy: 0.8577\n",
            "Epoch 46/100\n",
            "1469/1469 [==============================] - 63s 43ms/step - loss: 0.5982 - sparse_categorical_accuracy: 0.8897 - val_loss: 0.6279 - val_sparse_categorical_accuracy: 0.8807\n",
            "Epoch 47/100\n",
            "1469/1469 [==============================] - 64s 44ms/step - loss: 0.5948 - sparse_categorical_accuracy: 0.8904 - val_loss: 0.6738 - val_sparse_categorical_accuracy: 0.8667\n",
            "Epoch 48/100\n",
            "1469/1469 [==============================] - 64s 43ms/step - loss: 0.5909 - sparse_categorical_accuracy: 0.8929 - val_loss: 0.6637 - val_sparse_categorical_accuracy: 0.8763\n",
            "Epoch 49/100\n",
            "1469/1469 [==============================] - 63s 43ms/step - loss: 0.5935 - sparse_categorical_accuracy: 0.8905 - val_loss: 0.6797 - val_sparse_categorical_accuracy: 0.8620\n",
            "Epoch 50/100\n",
            "1469/1469 [==============================] - 65s 44ms/step - loss: 0.5907 - sparse_categorical_accuracy: 0.8920 - val_loss: 0.6316 - val_sparse_categorical_accuracy: 0.8820\n",
            "Epoch 51/100\n",
            "1469/1469 [==============================] - 64s 43ms/step - loss: 0.5836 - sparse_categorical_accuracy: 0.8943 - val_loss: 0.5963 - val_sparse_categorical_accuracy: 0.8963\n",
            "Epoch 52/100\n",
            "1469/1469 [==============================] - 64s 44ms/step - loss: 0.5890 - sparse_categorical_accuracy: 0.8929 - val_loss: 0.6387 - val_sparse_categorical_accuracy: 0.8847\n",
            "Epoch 53/100\n",
            "1469/1469 [==============================] - 64s 43ms/step - loss: 0.5834 - sparse_categorical_accuracy: 0.8936 - val_loss: 0.7081 - val_sparse_categorical_accuracy: 0.8600\n",
            "Epoch 54/100\n",
            "1469/1469 [==============================] - 63s 43ms/step - loss: 0.5805 - sparse_categorical_accuracy: 0.8958 - val_loss: 0.6133 - val_sparse_categorical_accuracy: 0.8837\n",
            "Epoch 55/100\n",
            "1469/1469 [==============================] - 64s 43ms/step - loss: 0.5795 - sparse_categorical_accuracy: 0.8950 - val_loss: 0.6284 - val_sparse_categorical_accuracy: 0.8800\n",
            "Epoch 56/100\n",
            "1469/1469 [==============================] - 64s 43ms/step - loss: 0.5803 - sparse_categorical_accuracy: 0.8950 - val_loss: 0.6699 - val_sparse_categorical_accuracy: 0.8657\n",
            "Epoch 57/100\n",
            "1469/1469 [==============================] - 64s 43ms/step - loss: 0.5769 - sparse_categorical_accuracy: 0.8946 - val_loss: 0.5904 - val_sparse_categorical_accuracy: 0.8943\n",
            "Epoch 58/100\n",
            "1469/1469 [==============================] - 63s 43ms/step - loss: 0.5765 - sparse_categorical_accuracy: 0.8959 - val_loss: 0.6441 - val_sparse_categorical_accuracy: 0.8790\n",
            "Epoch 59/100\n",
            "1469/1469 [==============================] - 65s 44ms/step - loss: 0.5715 - sparse_categorical_accuracy: 0.8965 - val_loss: 0.6284 - val_sparse_categorical_accuracy: 0.8817\n",
            "Epoch 60/100\n",
            "1469/1469 [==============================] - 64s 43ms/step - loss: 0.5724 - sparse_categorical_accuracy: 0.8976 - val_loss: 0.6370 - val_sparse_categorical_accuracy: 0.8743\n",
            "Epoch 61/100\n",
            "1469/1469 [==============================] - 64s 44ms/step - loss: 0.5709 - sparse_categorical_accuracy: 0.8991 - val_loss: 0.6604 - val_sparse_categorical_accuracy: 0.8777\n",
            "Epoch 62/100\n",
            "1469/1469 [==============================] - 64s 43ms/step - loss: 0.5701 - sparse_categorical_accuracy: 0.8969 - val_loss: 0.6309 - val_sparse_categorical_accuracy: 0.8833\n",
            "Epoch 63/100\n",
            "1469/1469 [==============================] - 64s 43ms/step - loss: 0.5640 - sparse_categorical_accuracy: 0.8983 - val_loss: 0.6005 - val_sparse_categorical_accuracy: 0.8893\n",
            "Epoch 64/100\n",
            "1469/1469 [==============================] - 64s 43ms/step - loss: 0.5682 - sparse_categorical_accuracy: 0.8978 - val_loss: 0.6162 - val_sparse_categorical_accuracy: 0.8870\n",
            "Epoch 65/100\n",
            "1469/1469 [==============================] - 64s 43ms/step - loss: 0.5702 - sparse_categorical_accuracy: 0.8969 - val_loss: 0.6412 - val_sparse_categorical_accuracy: 0.8720\n",
            "Epoch 66/100\n",
            "1469/1469 [==============================] - 64s 43ms/step - loss: 0.5655 - sparse_categorical_accuracy: 0.8981 - val_loss: 0.6304 - val_sparse_categorical_accuracy: 0.8807\n",
            "Epoch 67/100\n",
            "1469/1469 [==============================] - 65s 44ms/step - loss: 0.5635 - sparse_categorical_accuracy: 0.8982 - val_loss: 0.5499 - val_sparse_categorical_accuracy: 0.9060\n",
            "Epoch 68/100\n",
            "1469/1469 [==============================] - 64s 44ms/step - loss: 0.5579 - sparse_categorical_accuracy: 0.9001 - val_loss: 0.6872 - val_sparse_categorical_accuracy: 0.8610\n",
            "Epoch 69/100\n",
            "1469/1469 [==============================] - 64s 44ms/step - loss: 0.5571 - sparse_categorical_accuracy: 0.9000 - val_loss: 0.6135 - val_sparse_categorical_accuracy: 0.8840\n",
            "Epoch 70/100\n",
            "1469/1469 [==============================] - 64s 44ms/step - loss: 0.5529 - sparse_categorical_accuracy: 0.9009 - val_loss: 0.6226 - val_sparse_categorical_accuracy: 0.8787\n",
            "Epoch 71/100\n",
            "1469/1469 [==============================] - 63s 43ms/step - loss: 0.5623 - sparse_categorical_accuracy: 0.8979 - val_loss: 0.6071 - val_sparse_categorical_accuracy: 0.8823\n",
            "Epoch 72/100\n",
            "1469/1469 [==============================] - 63s 43ms/step - loss: 0.5538 - sparse_categorical_accuracy: 0.9002 - val_loss: 0.5789 - val_sparse_categorical_accuracy: 0.8973\n",
            "Epoch 73/100\n",
            "1469/1469 [==============================] - 64s 43ms/step - loss: 0.5571 - sparse_categorical_accuracy: 0.8999 - val_loss: 0.5821 - val_sparse_categorical_accuracy: 0.8977\n",
            "Epoch 74/100\n",
            "1469/1469 [==============================] - 64s 44ms/step - loss: 0.5524 - sparse_categorical_accuracy: 0.9011 - val_loss: 0.7118 - val_sparse_categorical_accuracy: 0.8613\n",
            "Epoch 75/100\n",
            "1469/1469 [==============================] - 64s 43ms/step - loss: 0.5568 - sparse_categorical_accuracy: 0.8991 - val_loss: 0.5869 - val_sparse_categorical_accuracy: 0.8953\n",
            "Epoch 76/100\n",
            "1469/1469 [==============================] - 64s 44ms/step - loss: 0.5546 - sparse_categorical_accuracy: 0.9012 - val_loss: 0.6124 - val_sparse_categorical_accuracy: 0.8883\n",
            "Epoch 77/100\n",
            "1469/1469 [==============================] - 64s 43ms/step - loss: 0.5493 - sparse_categorical_accuracy: 0.9032 - val_loss: 0.5914 - val_sparse_categorical_accuracy: 0.8933\n",
            "Epoch 78/100\n",
            "1469/1469 [==============================] - 63s 43ms/step - loss: 0.5504 - sparse_categorical_accuracy: 0.9025 - val_loss: 0.5880 - val_sparse_categorical_accuracy: 0.8907\n",
            "Epoch 79/100\n",
            "1469/1469 [==============================] - 64s 43ms/step - loss: 0.5528 - sparse_categorical_accuracy: 0.8996 - val_loss: 0.5206 - val_sparse_categorical_accuracy: 0.9100\n",
            "Epoch 80/100\n",
            "1469/1469 [==============================] - 64s 43ms/step - loss: 0.5471 - sparse_categorical_accuracy: 0.9034 - val_loss: 0.5872 - val_sparse_categorical_accuracy: 0.8913\n",
            "Epoch 81/100\n",
            "1469/1469 [==============================] - 64s 43ms/step - loss: 0.5450 - sparse_categorical_accuracy: 0.9035 - val_loss: 0.7057 - val_sparse_categorical_accuracy: 0.8580\n",
            "Epoch 82/100\n",
            "1469/1469 [==============================] - 64s 43ms/step - loss: 0.5462 - sparse_categorical_accuracy: 0.9017 - val_loss: 0.5587 - val_sparse_categorical_accuracy: 0.9017\n",
            "Epoch 83/100\n",
            "1469/1469 [==============================] - 64s 44ms/step - loss: 0.5463 - sparse_categorical_accuracy: 0.9016 - val_loss: 0.6262 - val_sparse_categorical_accuracy: 0.8800\n",
            "Epoch 84/100\n",
            "1469/1469 [==============================] - 63s 43ms/step - loss: 0.5460 - sparse_categorical_accuracy: 0.9006 - val_loss: 0.6471 - val_sparse_categorical_accuracy: 0.8753\n",
            "Epoch 85/100\n",
            "1469/1469 [==============================] - 63s 43ms/step - loss: 0.5458 - sparse_categorical_accuracy: 0.9012 - val_loss: 0.7097 - val_sparse_categorical_accuracy: 0.8507\n",
            "Epoch 86/100\n",
            "1469/1469 [==============================] - 64s 43ms/step - loss: 0.5371 - sparse_categorical_accuracy: 0.9051 - val_loss: 0.6050 - val_sparse_categorical_accuracy: 0.8893\n",
            "Epoch 87/100\n",
            "1469/1469 [==============================] - 64s 43ms/step - loss: 0.5464 - sparse_categorical_accuracy: 0.9021 - val_loss: 0.6005 - val_sparse_categorical_accuracy: 0.8860\n",
            "Epoch 88/100\n",
            "1469/1469 [==============================] - 64s 43ms/step - loss: 0.5425 - sparse_categorical_accuracy: 0.9034 - val_loss: 0.5995 - val_sparse_categorical_accuracy: 0.8850\n",
            "Epoch 89/100\n",
            "1469/1469 [==============================] - 64s 43ms/step - loss: 0.5427 - sparse_categorical_accuracy: 0.9029 - val_loss: 0.6063 - val_sparse_categorical_accuracy: 0.8893\n",
            "Epoch 90/100\n",
            "1469/1469 [==============================] - 64s 44ms/step - loss: 0.5378 - sparse_categorical_accuracy: 0.9042 - val_loss: 0.5591 - val_sparse_categorical_accuracy: 0.8953\n",
            "Epoch 91/100\n",
            "1469/1469 [==============================] - 64s 43ms/step - loss: 0.5321 - sparse_categorical_accuracy: 0.9057 - val_loss: 0.6030 - val_sparse_categorical_accuracy: 0.8817\n",
            "Epoch 92/100\n",
            "1469/1469 [==============================] - 64s 44ms/step - loss: 0.5393 - sparse_categorical_accuracy: 0.9046 - val_loss: 0.6124 - val_sparse_categorical_accuracy: 0.8810\n",
            "Epoch 93/100\n",
            "1469/1469 [==============================] - 64s 43ms/step - loss: 0.5376 - sparse_categorical_accuracy: 0.9043 - val_loss: 0.5886 - val_sparse_categorical_accuracy: 0.8903\n",
            "Epoch 94/100\n",
            "1469/1469 [==============================] - 63s 43ms/step - loss: 0.5336 - sparse_categorical_accuracy: 0.9046 - val_loss: 0.6499 - val_sparse_categorical_accuracy: 0.8753\n",
            "Epoch 95/100\n",
            "1469/1469 [==============================] - 64s 44ms/step - loss: 0.5334 - sparse_categorical_accuracy: 0.9064 - val_loss: 0.6275 - val_sparse_categorical_accuracy: 0.8777\n",
            "Epoch 96/100\n",
            "1469/1469 [==============================] - 63s 43ms/step - loss: 0.5296 - sparse_categorical_accuracy: 0.9066 - val_loss: 0.5893 - val_sparse_categorical_accuracy: 0.8887\n",
            "Epoch 97/100\n",
            "1469/1469 [==============================] - 64s 43ms/step - loss: 0.5376 - sparse_categorical_accuracy: 0.9039 - val_loss: 0.5648 - val_sparse_categorical_accuracy: 0.8997\n",
            "Epoch 98/100\n",
            "1469/1469 [==============================] - 64s 44ms/step - loss: 0.5292 - sparse_categorical_accuracy: 0.9065 - val_loss: 0.6226 - val_sparse_categorical_accuracy: 0.8827\n",
            "Epoch 99/100\n",
            "1469/1469 [==============================] - 64s 43ms/step - loss: 0.5256 - sparse_categorical_accuracy: 0.9083 - val_loss: 0.6379 - val_sparse_categorical_accuracy: 0.8800\n",
            "Epoch 100/100\n",
            "1469/1469 [==============================] - 64s 43ms/step - loss: 0.5345 - sparse_categorical_accuracy: 0.9042 - val_loss: 0.5717 - val_sparse_categorical_accuracy: 0.9000\n",
            "Model: \"res_net18\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_18 (Conv2D)          multiple                  1728      \n",
            "                                                                 \n",
            " batch_normalization (Batch  multiple                  256       \n",
            " Normalization)                                                  \n",
            "                                                                 \n",
            " activation_6 (Activation)   multiple                  0         \n",
            "                                                                 \n",
            " sequential_2 (Sequential)   (None, None, None, 512)   11176448  \n",
            "                                                                 \n",
            " global_average_pooling2d_2  multiple                  0         \n",
            "  (GlobalAveragePooling2D)                                       \n",
            "                                                                 \n",
            " dense (Dense)               multiple                  5130      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 11183562 (42.66 MB)\n",
            "Trainable params: 11173962 (42.63 MB)\n",
            "Non-trainable params: 9600 (37.50 KB)\n",
            "_________________________________________________________________\n",
            "313/313 [==============================] - 4s 14ms/step - loss: 0.5889 - sparse_categorical_accuracy: 0.8938\n",
            "0.8938000202178955\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T4JfEh7kvx6m"
      },
      "source": [
        "The image classifier is now trained to ~98% accuracy on this dataset. To learn more, read the [TensorFlow tutorials](https://www.tensorflow.org/tutorials)."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}